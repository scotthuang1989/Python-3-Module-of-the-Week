<<<<<<< Updated upstream:developer_tools/Profile_Time_Memory_python.ipynb
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Time\n",
    "[Timeit(for small piece of code)](#timeit)\n",
    "\n",
    "[cProfile(function level statistic)](#CProfile)\n",
    "\n",
    "[line_profiler(line level profiling)](#line_profiler)\n",
    "\n",
    "# Profile Memory\n",
    "[memory_profiler(function and line level)](#memory_profiler)\n",
    "\n",
    "[profile object reference: objgraph](#objgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"timeit\"></a>\n",
    "## Timeit(for small piece of code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python comes with a module called timeit. You can use it to time small code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run it on command line interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "python -m timeit -s \"[ord(x) for x in 'abcdfghi']\"\n",
    "\n",
    ">#100000000 loops, best of 3: 0.0115 usec per loop\n",
    "\n",
    "python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "\n",
    ">#python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "100000000 loops, best of 3: 0.0119 usec per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-line statement may be given by specifying each line as a separate statement argument; indented lines are possible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly.\n",
    "\n",
    "If -n is not given, a suitable number of loops is calculated by trying successive powers of 10 until the total time is at least 0.2 seconds.\n",
    "\n",
    "default_timer() measurements can be affected by other programs running on the same machine, so the best thing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option is good for this; the default of 3 repetitions is probably enough in most cases. You can use time.process_time() to measure CPU time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import timeit for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3263827509999828\n"
     ]
    }
   ],
   "source": [
    "def my_function():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    import timeit\n",
    "    setup = \"from __main__ import my_function\"\n",
    "    print(timeit.timeit(\"my_function()\", setup=setup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 312 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CProfile\"></a>\n",
    "## CProfile(function level statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python comes with its own code profilers built-in. There is the profile module and the cProfile module. The profile module is pure Python, but it will add a lot of overhead to anything you profile, so it’s usually recommended that you go with cProfile, which has a similar interface but is much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile a script on command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate profile file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -m cProfile [-o output_file] [-s sort_order] myscript.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyze output profile file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('profiledata001.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\http\\client.py:1337(CannotSendRequest)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\parser.py:298(_convert)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\compat\\_inspect.py:144(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\computation\\ops.py:32(UndefinedVariableError)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\arrayprint.py:711(IntegerFormat)\n",
      "      932    0.109    0.000    0.109    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:491(_MergeOperation)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\six.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\ctypes\\wintypes.py:155(WIN32_FIND_DATAW)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\config.py:223(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\pickle.py:219(_Unframer)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\tseries\\offsets.py:1009(<listcomp>)\n",
      "        1    0.000    0.000    0.006    0.006 E:\\python\\lib\\email\\utils.py:5(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\unittest\\suite.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\relativedelta.py:18(relativedelta)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\json\\encoder.py:67(JSONEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:5(DefragResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\urllib\\parse.py:243(SplitResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\io\\formats\\format.py:298(EastAsianTextAdjustment)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\util\\_validators.py:4(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\email\\feedparser.py:44(BufferedSubFile)\n",
      "      163    0.000    0.000    0.000    0.000 E:\\python\\lib\\socket.py:75(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\_internal.py:671(TooHardError)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\difflib.py:27(<module>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print profile\n",
    "p.print_stats(0.01) # check reference for parameter, 0.01 mean only print 1% of output, because complete log is too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meaning of Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ncalls\n",
    "    * for the number of calls.\n",
    "* tottime\n",
    "    * for the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
    "* percall\n",
    "    * is the quotient of tottime divided by ncalls\n",
    "* cumtime\n",
    "    * is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
    "* percall\n",
    "    * is the quotient of cumtime divided by primitive calls\n",
    "* filename:lineno(function)\n",
    "    * provides the respective data of each function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can sort output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sort_stats(\"cumtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    427/1    0.116    0.000 2867.919 2867.919 {built-in method exec}\n",
      "        1    0.107    0.107 2867.819 2867.819 run.py:1(<module>)\n",
      "        1    0.709    0.709 2862.906 2862.906 run.py:9(start_analyze_log)\n",
      "      188    0.090    0.000 2079.355   11.060 E:\\python\\lib\\site-packages\\bs4\\__init__.py:87(__init__)\n",
      "      188    1.064    0.006 2078.857   11.058 E:\\python\\lib\\site-packages\\bs4\\__init__.py:285(_feed)\n",
      "      188  207.396    1.103 2077.793   11.052 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:121(feed)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      " 26358783  287.394    0.000 1053.401    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:145(start)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      " 26358783  126.567    0.000  603.223    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:194(end)\n",
      " 26358783   61.671    0.000  591.798    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:447(handle_starttag)\n",
      " 79076537  183.151    0.000  579.789    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:337(endData)\n",
      "   772111    1.478    0.000  523.556    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1298(find_all)\n",
      "   772111    5.226    0.000  522.078    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:518(_find_all)\n",
      "   772111    6.870    0.000  482.632    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1801(__init__)\n",
      "   288448  122.510    0.000  475.762    0.002 E:\\python\\lib\\site-packages\\bs4\\element.py:543(<genexpr>)\n",
      "117121588  339.989    0.000  340.531    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:1323(descendants)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      " 52614596   76.026    0.000  223.218    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:367(object_was_parsed)\n",
      "131588163  197.993    0.000  201.233    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:203(setup)\n",
      "      147    0.007    0.000  196.189    1.335 E:\\data\\burdenoff\\dataanalysis\\model.py:190(update_testresult)\n",
      "      140    0.192    0.001  195.298    1.395 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:51(update_db_helper)\n",
      " 26358971  143.175    0.000  192.338    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:813(__init__)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.print_stats(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can also add resttriction when print states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 50 due to restriction <'dataanalysis'>\n",
      "   List reduced from 50 to 5 due to restriction <0.1>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my only scipt in in this path: E:\\data\\burdenoff\\dataanalysis, so I can only print analysis on my own code\n",
    "# it can help to find the issue more faster\n",
    "p.print_stats(\"dataanalysis\",0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other thing you can do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[official documents](https://docs.python.org/3.5/library/profile.html#the-python-profilers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"line_profiler\"></a>\n",
    "## line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this is a 3rd party package install with: ***pip install line_profiler***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually use the line_profiler, we will need some code to profile. But first, I need to explain how line_profiler works when you call it on the command line. You will actually be calling line_profiler by calling the kernprof script. I thought that was a bit confusing the first time I used it, but that’s just the way it works. Here’s the normal way to use it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```kernprof -l silly_functions.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when it finishes: Wrote profile results to silly_functions.py.lprof(filename.lprof). This is a binary file that we can’t view directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note**:\n",
    " next few cell run be run under terminal, don't run it in notebok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run kernprof though, it will actually inject an instance of LineProfiler into your script’s __builtins__ namespace. The instance will be named profile and is meant to be used as a decorator. With that in mind, we can actually write our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# silly_functions.py\n",
    "import time\n",
    " \n",
    "@profile\n",
    "def fast_function():\n",
    "    print(\"I'm a fast function!\")\n",
    " \n",
    "@profile\n",
    "def slow_function():\n",
    "    time.sleep(2)\n",
    "    print(\"I'm a slow function\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    fast_function()\n",
    "    slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command：python -m line_profiler script_to_profile.py.lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm a fast function!\n",
    "# I'm a slow function\n",
    "# Wrote profile results to silly_functions.py.lprof\n",
    "# Timer unit: 1e-06 s\n",
    " \n",
    "# Total time: 3.4e-05 s\n",
    "# File: silly_functions.py\n",
    "# Function: fast_function at line 3\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      3                                           @profile\n",
    "#      4                                           def fast_function():\n",
    "#      5         1           34     34.0    100.0      print(\"I'm a fast function!\")\n",
    " \n",
    "# Total time: 2.001 s\n",
    "# File: silly_functions.py\n",
    "# Function: slow_function at line 7\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      7                                           @profile\n",
    "#      8                                           def slow_function():\n",
    "#      9         1      2000942 2000942.0    100.0      time.sleep(2)\n",
    "#     10         1           59     59.0      0.0      print(\"I'm a slow function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the source code is printed out with the timing information for each line. There are six columns of information here. Let’s find out what each one means.\n",
    "\n",
    "    Line # – The line number of the code that was profiled\n",
    "    Hits – The number of times that particular line was executed\n",
    "    Time – The total amount of time the line took to execute (in the timer’s unit). The timer unit can be seen at the beginning of the output\n",
    "    Per Hit – The average amount of time that line of code took to execute (in timer units)\n",
    "    % Time – The percentage of time spent on the line relative to the total amount of time spent in said function\n",
    "    Line Contents – The actual source code that was executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook magic: %lprun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to be an IPython user, then you might want to know that IPython has a magic command (%lprun) that allows you to specify functions to profile and even which statement to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"memory_profiler\"></a>\n",
    "## memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great 3rd party profiling package is memory_profiler. The memory_profiler module can be used for monitoring memory consumption in a process or you can use it for a line-by-line analysis of the memory consumption of your code. Since it’s not included with Python, we’ll have to install it. You can use pip for this:\n",
    "\n",
    "\n",
    "```pip install memory_profiler```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it’s installed, we need some code to run it against. The memory_profiler actually works in much the same way as line_profiler in that when you run it, memory_profiler will inject an instance of itself into __builtins__ named profile that you are supposed to use as a decorator on the function you are profiling. Here’s a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  command line usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* command:  python -m memory_profiler example.py\n",
    "* you need add function decorator for function you want to profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def my_func():\n",
    "    a = [1] * (10 ** 6)\n",
    "    b = [2] * (2 * 10 ** 7)\n",
    "    del b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to have full memory usage reports as a function of time (not line-by-line) of external processes (be it Python scripts or not). In this case the executable mprof might be useful. Use it like:\n",
    "\n",
    "command:    \n",
    "mprof run <executable>    \n",
    "mprof plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** note***:\n",
    "1. my preferred way of runing it is:    \n",
    "mprof run xxx | tee $(date + \"%Y_%m_%d_%I_%M_%p\").log\n",
    "\n",
    "in this way, we can keep both picture and text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"objgraph\"></a>\n",
    "## objgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup\n",
    "**Note**:\n",
    "don't forget to install `graphviz` and `xdot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Time\n",
    "[Timeit(for small piece of code)](#timeit)\n",
    "\n",
    "[cProfile(function level statistic)](#CProfile)\n",
    "\n",
    "[line_profiler(line level profiling)](#line_profiler)\n",
    "\n",
    "# Profile Memory\n",
    "[memory_profiler(function and line level)](#memory_profiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"timeit\"></a>\n",
    "## Timeit(for small piece of code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python comes with a module called timeit. You can use it to time small code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run it on command line interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "python -m timeit -s \"[ord(x) for x in 'abcdfghi']\"\n",
    "\n",
    ">#100000000 loops, best of 3: 0.0115 usec per loop\n",
    "\n",
    "python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "\n",
    ">#python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "100000000 loops, best of 3: 0.0119 usec per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-line statement may be given by specifying each line as a separate statement argument; indented lines are possible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly.\n",
    "\n",
    "If -n is not given, a suitable number of loops is calculated by trying successive powers of 10 until the total time is at least 0.2 seconds.\n",
    "\n",
    "default_timer() measurements can be affected by other programs running on the same machine, so the best thing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option is good for this; the default of 3 repetitions is probably enough in most cases. You can use time.process_time() to measure CPU time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import timeit for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3263827509999828\n"
     ]
    }
   ],
   "source": [
    "def my_function():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    import timeit\n",
    "    setup = \"from __main__ import my_function\"\n",
    "    print(timeit.timeit(\"my_function()\", setup=setup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 312 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CProfile\"></a>\n",
    "## CProfile(function level statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python comes with its own code profilers built-in. There is the profile module and the cProfile module. The profile module is pure Python, but it will add a lot of overhead to anything you profile, so it’s usually recommended that you go with cProfile, which has a similar interface but is much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile a script on command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate profile file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -m cProfile [-o output_file] [-s sort_order] myscript.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyze output profile file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('profiledata001.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\http\\client.py:1337(CannotSendRequest)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\parser.py:298(_convert)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\compat\\_inspect.py:144(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\computation\\ops.py:32(UndefinedVariableError)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\arrayprint.py:711(IntegerFormat)\n",
      "      932    0.109    0.000    0.109    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:491(_MergeOperation)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\six.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\ctypes\\wintypes.py:155(WIN32_FIND_DATAW)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\config.py:223(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\pickle.py:219(_Unframer)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\tseries\\offsets.py:1009(<listcomp>)\n",
      "        1    0.000    0.000    0.006    0.006 E:\\python\\lib\\email\\utils.py:5(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\unittest\\suite.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\relativedelta.py:18(relativedelta)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\json\\encoder.py:67(JSONEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:5(DefragResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\urllib\\parse.py:243(SplitResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\io\\formats\\format.py:298(EastAsianTextAdjustment)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\util\\_validators.py:4(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\email\\feedparser.py:44(BufferedSubFile)\n",
      "      163    0.000    0.000    0.000    0.000 E:\\python\\lib\\socket.py:75(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\_internal.py:671(TooHardError)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\difflib.py:27(<module>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print profile\n",
    "p.print_stats(0.01) # check reference for parameter, 0.01 mean only print 1% of output, because complete log is too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meaning of Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ncalls\n",
    "    * for the number of calls.\n",
    "* tottime\n",
    "    * for the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
    "* percall\n",
    "    * is the quotient of tottime divided by ncalls\n",
    "* cumtime\n",
    "    * is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
    "* percall\n",
    "    * is the quotient of cumtime divided by primitive calls\n",
    "* filename:lineno(function)\n",
    "    * provides the respective data of each function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can sort output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sort_stats(\"cumtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    427/1    0.116    0.000 2867.919 2867.919 {built-in method exec}\n",
      "        1    0.107    0.107 2867.819 2867.819 run.py:1(<module>)\n",
      "        1    0.709    0.709 2862.906 2862.906 run.py:9(start_analyze_log)\n",
      "      188    0.090    0.000 2079.355   11.060 E:\\python\\lib\\site-packages\\bs4\\__init__.py:87(__init__)\n",
      "      188    1.064    0.006 2078.857   11.058 E:\\python\\lib\\site-packages\\bs4\\__init__.py:285(_feed)\n",
      "      188  207.396    1.103 2077.793   11.052 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:121(feed)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      " 26358783  287.394    0.000 1053.401    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:145(start)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      " 26358783  126.567    0.000  603.223    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:194(end)\n",
      " 26358783   61.671    0.000  591.798    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:447(handle_starttag)\n",
      " 79076537  183.151    0.000  579.789    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:337(endData)\n",
      "   772111    1.478    0.000  523.556    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1298(find_all)\n",
      "   772111    5.226    0.000  522.078    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:518(_find_all)\n",
      "   772111    6.870    0.000  482.632    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1801(__init__)\n",
      "   288448  122.510    0.000  475.762    0.002 E:\\python\\lib\\site-packages\\bs4\\element.py:543(<genexpr>)\n",
      "117121588  339.989    0.000  340.531    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:1323(descendants)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      " 52614596   76.026    0.000  223.218    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:367(object_was_parsed)\n",
      "131588163  197.993    0.000  201.233    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:203(setup)\n",
      "      147    0.007    0.000  196.189    1.335 E:\\data\\burdenoff\\dataanalysis\\model.py:190(update_testresult)\n",
      "      140    0.192    0.001  195.298    1.395 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:51(update_db_helper)\n",
      " 26358971  143.175    0.000  192.338    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:813(__init__)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.print_stats(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can also add resttriction when print states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 50 due to restriction <'dataanalysis'>\n",
      "   List reduced from 50 to 5 due to restriction <0.1>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my only scipt in in this path: E:\\data\\burdenoff\\dataanalysis, so I can only print analysis on my own code\n",
    "# it can help to find the issue more faster\n",
    "p.print_stats(\"dataanalysis\",0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other thing you can do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[official documents](https://docs.python.org/3.5/library/profile.html#the-python-profilers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"line_profiler\"></a>\n",
    "## line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this is a 3rd party package install with: ***pip install line_profiler***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually use the line_profiler, we will need some code to profile. But first, I need to explain how line_profiler works when you call it on the command line. You will actually be calling line_profiler by calling the kernprof script. I thought that was a bit confusing the first time I used it, but that’s just the way it works. Here’s the normal way to use it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```kernprof -l silly_functions.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when it finishes: Wrote profile results to silly_functions.py.lprof(filename.lprof). This is a binary file that we can’t view directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note**:\n",
    " next few cell run be run under terminal, don't run it in notebok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run kernprof though, it will actually inject an instance of LineProfiler into your script’s __builtins__ namespace. The instance will be named profile and is meant to be used as a decorator. With that in mind, we can actually write our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silly_functions.py\n",
    "import time\n",
    " \n",
    "@profile\n",
    "def fast_function():\n",
    "    print(\"I'm a fast function!\")\n",
    " \n",
    "@profile\n",
    "def slow_function():\n",
    "    time.sleep(2)\n",
    "    print(\"I'm a slow function\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    fast_function()\n",
    "    slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command：python -m line_profiler script_to_profile.py.lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm a fast function!\n",
    "# I'm a slow function\n",
    "# Wrote profile results to silly_functions.py.lprof\n",
    "# Timer unit: 1e-06 s\n",
    " \n",
    "# Total time: 3.4e-05 s\n",
    "# File: silly_functions.py\n",
    "# Function: fast_function at line 3\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      3                                           @profile\n",
    "#      4                                           def fast_function():\n",
    "#      5         1           34     34.0    100.0      print(\"I'm a fast function!\")\n",
    " \n",
    "# Total time: 2.001 s\n",
    "# File: silly_functions.py\n",
    "# Function: slow_function at line 7\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      7                                           @profile\n",
    "#      8                                           def slow_function():\n",
    "#      9         1      2000942 2000942.0    100.0      time.sleep(2)\n",
    "#     10         1           59     59.0      0.0      print(\"I'm a slow function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the source code is printed out with the timing information for each line. There are six columns of information here. Let’s find out what each one means.\n",
    "\n",
    "    Line # – The line number of the code that was profiled\n",
    "    Hits – The number of times that particular line was executed\n",
    "    Time – The total amount of time the line took to execute (in the timer’s unit). The timer unit can be seen at the beginning of the output\n",
    "    Per Hit – The average amount of time that line of code took to execute (in timer units)\n",
    "    % Time – The percentage of time spent on the line relative to the total amount of time spent in said function\n",
    "    Line Contents – The actual source code that was executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook magic: %lprun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to be an IPython user, then you might want to know that IPython has a magic command (%lprun) that allows you to specify functions to profile and even which statement to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"memory_profiler\"></a>\n",
    "## memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great 3rd party profiling package is memory_profiler. The memory_profiler module can be used for monitoring memory consumption in a process or you can use it for a line-by-line analysis of the memory consumption of your code. Since it’s not included with Python, we’ll have to install it. You can use pip for this:\n",
    "\n",
    "\n",
    "```pip install memory_profiler```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it’s installed, we need some code to run it against. The memory_profiler actually works in much the same way as line_profiler in that when you run it, memory_profiler will inject an instance of itself into __builtins__ named profile that you are supposed to use as a decorator on the function you are profiling. Here’s a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  command line usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* command:  python -m memory_profiler example.py\n",
    "* you need add function decorator for function you want to profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def my_func():\n",
    "    a = [1] * (10 ** 6)\n",
    "    b = [2] * (2 * 10 ** 7)\n",
    "    del b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to have full memory usage reports as a function of time (not line-by-line) of external processes (be it Python scripts or not). In this case the executable mprof might be useful. Use it like:\n",
    "\n",
    "command:    \n",
    "mprof run <executable>    \n",
    "mprof plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** note***:\n",
    "1. my preferred way of runing it is:    \n",
    "mprof run xxx | tee $(date + \"%Y_%m_%d_%I_%M_%p\").log\n",
    "\n",
    "in this way, we can keep both picture and text analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> Stashed changes:Profile_Time_Memory_python.ipynb
